{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm.autonotebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split         # Split data into train and test set\n",
    "from sklearn.metrics import classification_report            # Summary of classifier performance\n",
    "\n",
    "from utils import get_df, evaluate_classifier\n",
    "\n",
    "# Automatically prints execution time for the individual cells\n",
    "%load_ext autotime\n",
    "\n",
    "# Automatically reloads functions defined in external files\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Set xarray to use html as display_style\n",
    "xr.set_options(display_style=\"html\")\n",
    "\n",
    "# Tell matplotlib to plot directly in the notebook\n",
    "%matplotlib inline  \n",
    "\n",
    "# The path to the project (so absoute file paths can be used throughout the notebook)\n",
    "PROJ_PATH = Path.cwd().parent\n",
    "\n",
    "# Mapping dict\n",
    "mapping_dict_crop_types = {\n",
    "    'Kartofler, stivelses-': 'Potato',\n",
    "    'Kartofler, lægge- (egen opformering)': 'Potato',\n",
    "    'Kartofler, andre': 'Potato',\n",
    "    'Kartofler, spise-': 'Potato',\n",
    "    'Kartofler, lægge- (certificerede)': 'Potato',\n",
    "    'Vårbyg': 'Spring barley',\n",
    "    'Vinterbyg': 'Winter barley',\n",
    "    'Vårhvede': 'Spring wheat',\n",
    "    'Vinterhvede': 'Winter wheat',\n",
    "    'Vinterrug': 'Winter rye',\n",
    "    'Vårhavre': 'Spring oat',\n",
    "    'Silomajs': 'Maize',\n",
    "    'Vinterraps': 'Rapeseed',\n",
    "    'Permanent græs, normalt udbytte': 'Permanent grass',\n",
    "    'Pil': 'Willow',\n",
    "    'Skovdrift, alm.': 'Forest'\n",
    "}\n",
    "\n",
    "# Set global seed for random generators\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Seed the random generators\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netcdf_path = (PROJ_PATH / 'data' / 'processed' / 'FieldPolygons2019_stats').with_suffix('.nc')\n",
    "ds = xr.open_dataset(netcdf_path, engine=\"h5netcdf\")\n",
    "ds  # Remember to close the dataset before the netcdf file can be rewritten in cells above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the xarray dataset to pandas dataframe\n",
    "df = ds.to_dataframe()\n",
    "df = df.reset_index()  # Removes MultiIndex\n",
    "df = df.drop(columns=['cvr', 'gb', 'gbanmeldt', 'journalnr', 'marknr', 'pass_mode', 'relative_orbit'])\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the df format to be used by scikit-learn\n",
    "for i, polarization in enumerate(['VV', 'VH', 'VV-VH']):\n",
    "    df_polarization = get_df(polygons_year=2019, \n",
    "                             satellite_dates=slice('2018-01-01', '2019-12-31'), \n",
    "                             fields='all', \n",
    "                             satellite='all', \n",
    "                             polarization=polarization,\n",
    "                             netcdf_path=netcdf_path)\n",
    "    \n",
    "    # Extract a mapping of field_ids to crop type\n",
    "    if i == 0:\n",
    "        df_sklearn = df_polarization[['field_id', 'afgkode', 'afgroede']]\n",
    "    \n",
    "    # Pivot the df (https://stackoverflow.com/a/37790707/12045808)\n",
    "    df_polarization = df_polarization.pivot(index='field_id', columns='date', values='stats_mean')\n",
    "    \n",
    "    # Add polarization to column names\n",
    "    df_polarization.columns = [str(col)[:10]+f'_{polarization}' for col in df_polarization.columns]  \n",
    "    \n",
    "    # Merge the polarization dataframes into one dataframe\n",
    "    df_polarization = df_polarization.reset_index()  # Creates new indices and a 'field_id' column (field id was used as indices before)\n",
    "    df_sklearn = pd.merge(df_sklearn, df_polarization, on='field_id') \n",
    "        \n",
    "# Drop fields having nan values\n",
    "df_sklearn = df_sklearn.dropna()\n",
    "\n",
    "# The merge operation for some reason made duplicates (there was a bug reported on this earlier), so drop duplicates and re-index the df\n",
    "df_sklearn = df_sklearn.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sklearn_remapped = df_sklearn.copy()\n",
    "\n",
    "df_sklearn_remapped.insert(3, 'Crop type', '')\n",
    "df_sklearn_remapped.insert(4, 'Label ID', 0)\n",
    "mapping_dict = {}\n",
    "class_names = [] \n",
    "i = 0\n",
    "for key, value in mapping_dict_crop_types.items():\n",
    "    df_sklearn_remapped.loc[df_sklearn_remapped['afgroede'] == key, 'Crop type'] = value \n",
    "    if value not in class_names:\n",
    "        class_names.append(value)\n",
    "        mapping_dict[value] = i\n",
    "        i += 1\n",
    "    \n",
    "for key, value in mapping_dict.items():\n",
    "    df_sklearn_remapped.loc[df_sklearn_remapped['Crop type'] == key, 'Label ID'] = value \n",
    "print(f\"Crop types: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = df_sklearn_remapped.values\n",
    "\n",
    "# Define the independent variables as features.\n",
    "X = np.float32(array[:,5:])  # The features \n",
    "\n",
    "# Define the target (dependent) variable as labels.\n",
    "y = np.int8(array[:,4])  # The column 'afgkode'\n",
    "\n",
    "# Create a train/test split using 30% test size.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "print(f\"Train samples:      {len(y_train)}\")\n",
    "print(f\"Test samples:       {len(y_test)}\")\n",
    "print(f\"Number of features: {len(X[0,:])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression          \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# From https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
    "# Note: GaussianClassifier does not work (maybe requires too much training - kernel restarts in jupyter)\n",
    "names = [\n",
    "    \"Nearest Neighbors\", \n",
    "    \"Decision Tree\", \n",
    "    \"Random Forest\", \n",
    "    \"Logistic Regression\",\n",
    "    \"Linear SVM\", \n",
    "    \"RBF SVM\",\n",
    "    \"Neural Net\"\n",
    "    ]\n",
    "\n",
    "N_JOBS=24\n",
    "classifiers = [\n",
    "    GridSearchCV(KNeighborsClassifier(), \n",
    "                 param_grid={'n_neighbors': [2, 3, 4, 5, 6, 7, 8]}, \n",
    "                 refit=True, cv=5, n_jobs=N_JOBS),\n",
    "    GridSearchCV(DecisionTreeClassifier(random_state=RANDOM_SEED), \n",
    "                 param_grid={'max_depth': [2, 3, 4, 5, 6, 7, 8]}, \n",
    "                 refit=True, cv=5, n_jobs=N_JOBS),\n",
    "    GridSearchCV(RandomForestClassifier(random_state=RANDOM_SEED), \n",
    "                 param_grid={'max_depth': [2, 3, 4, 5, 6, 7, 8], \n",
    "                             'n_estimators': [6, 8, 10, 12, 14], \n",
    "                             'max_features': [1, 2, 3]},\n",
    "                 refit=True, cv=5, n_jobs=N_JOBS),\n",
    "    GridSearchCV(LogisticRegression(random_state=RANDOM_SEED),\n",
    "                 param_grid={'C': [1e-4, 1e-3, 1e-2, 1e-1, 1],\n",
    "                             'penalty': ['l1', 'l2']},\n",
    "                 refit=True, cv=5, n_jobs=N_JOBS),\n",
    "    GridSearchCV(SVC(kernel='linear', random_state=RANDOM_SEED),\n",
    "                 param_grid={'C': [1e-1, 1, 1e1, 1e2, 1e3, 1e4]},\n",
    "                 refit=True, cv=5, n_jobs=N_JOBS),\n",
    "    GridSearchCV(SVC(kernel='rbf', random_state=RANDOM_SEED),\n",
    "                 param_grid={'C': [1e-1, 1, 1e1, 1e2, 1e3, 1e4]},\n",
    "                 refit=True, cv=5, n_jobs=N_JOBS),\n",
    "    GridSearchCV(MLPClassifier(max_iter=1000, random_state=RANDOM_SEED),\n",
    "                 param_grid={'alpha': [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1],\n",
    "                             'hidden_layer_sizes': [(50,50,50), (100,)],\n",
    "                             'activation': ['tanh', 'relu'],\n",
    "                             'learning_rate': ['constant','adaptive']},\n",
    "                 refit=True, cv=5, n_jobs=N_JOBS)\n",
    "    ]\n",
    "\n",
    "clf_trained_dict = {}\n",
    "report_dict = {}\n",
    "cm_dict = {}\n",
    "\n",
    "# TODO: Also calculate uncertainties - ie. use multiple random seeds.\n",
    "#       Create df (with cols [Clf_name, Random_seed, Acc., Prec., Recall, F1-score]) and loop over random seeds\n",
    "#       See following on how to format pandas dataframe to get the uncertainties into the df\n",
    "#       https://stackoverflow.com/questions/46584736/pandas-change-between-mean-std-and-plus-minus-notations\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "    # Evaluate classifier\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    print(f\"Evaluating classifier: {name}\")\n",
    "    clf_trained, _, _, results_report, cnf_matrix = evaluate_classifier(clf, X_train, X_test, y_train, y_test, class_names, feature_scale=True)      \n",
    "    print(f\"The best parameters are {clf_trained.best_params_} with a score of {clf_trained.best_score_:2f}\")\n",
    "    \n",
    "    # Save results in dicts\n",
    "    clf_trained_dict[name] = clf_trained\n",
    "    report_dict[name] = results_report\n",
    "    cm_dict[name] = cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show performance of all classifiers on entire dataset\n",
    "# Loop over cm_dict and get pycm from each. Create a df with results from each classifier, and send output to latex.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show performance on different classes with best performing classifier\n",
    "\n",
    "# Get classfication report as pandas df\n",
    "df_results = pd.DataFrame(report_dict['RBF SVM']).transpose()  \n",
    "\n",
    "# Round the values to 2 decimals\n",
    "df_results = df_results.astype({'support': 'int32'}).round(2) \n",
    "\n",
    "# Remove samples from 'macro avg' and 'weighed avg'\n",
    "df_results.loc[df_results.index == 'accuracy', 'precision'] = ''  \n",
    "df_results.loc[df_results.index == 'accuracy', 'recall'] = ''  \n",
    "df_results.loc[df_results.index == 'accuracy', 'support'] = df_results.loc[df_results.index == 'macro avg', 'support'].values\n",
    "\n",
    "# Rename the support column to 'samples'\n",
    "df_results = df_results.rename(columns={'precision': 'Prec.',\n",
    "                                        'recall': 'Recall',\n",
    "                                        'f1-score': 'F1-score',\n",
    "                                        'support': 'Samples'},\n",
    "                               index={'accuracy': 'Overall acc.',\n",
    "                                      'macro avg': 'Macro avg.',\n",
    "                                      'weighted avg': 'Weighted avg.'})\n",
    "\n",
    "\n",
    "# Print df in latex format (I normally add a /midrule above 'Macro avg.' and delete 'Overall acc.')\n",
    "pd.options.display.float_format = '{:.2f}'.format  # Show 2 decimals\n",
    "print(df_results.to_latex(index=True))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Idea: Maybe make a utils folder, with a plotting module, evaluation module etc.. The below here should \n",
    "#       then be put in the plotting module. \n",
    "mean_test_scores = grid_trained.cv_results_['mean_test_score']\n",
    "mean_fit_times = grid_trained.cv_results_['mean_fit_time']\n",
    "param_columns = list(grid_trained.cv_results_['params'][0].keys())\n",
    "result_columns = ['mean_fit_time', 'mean_test_score']\n",
    "num_fits = len(grid_trained.cv_results_['params'])\n",
    "\n",
    "df_cv_results = pd.DataFrame(0, index=range(num_fits), columns=param_columns+result_columns)\n",
    "for i, param_set in enumerate(grid_trained.cv_results_['params']):\n",
    "    for param, value in param_set.items():\n",
    "        df_cv_results.loc[i, param] = value \n",
    "    df_cv_results.loc[i, 'mean_test_score'] = mean_test_scores[i]\n",
    "    df_cv_results.loc[i, 'mean_fit_time'] = mean_fit_times[i]\n",
    "    \n",
    "df_heatmap_mean_score = df_cv_results.pivot(index='C', columns='gamma', values='mean_test_score')\n",
    "plt.figure(figsize=(10,8))\n",
    "ax = sns.heatmap(df_heatmap_mean_score, annot=True, cmap=plt.cm.Blues)\n",
    "\n",
    "df_heatmap_fit_time = df_cv_results.pivot(index='C', columns='gamma', values='mean_fit_time')\n",
    "plt.figure(figsize=(10,8))\n",
    "ax = sns.heatmap(df_heatmap_fit_time.astype('int64'), annot=True, fmt='d', cmap=plt.cm.Blues_r)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from pycm import ConfusionMatrix\n",
    "except:\n",
    "    !pip install pycm\n",
    "    from pycm import ConfusionMatrix\n",
    "\n",
    "def numpy_confusion_matrix_to_pycm(confusion_matrix_numpy, labels=None):\n",
    "    \"\"\"Create a pycm confusion matrix from a NumPy confusion matrix\n",
    "    Creates a confusion matrix object with the pycm library based on a confusion matrix as 2D NumPy array (such as\n",
    "    the one generated by the sklearn confusion matrix function).\n",
    "    See more about pycm confusion matrices at `pycm`_, and see more\n",
    "    about sklearn confusion matrices at `sklearn confusion matrix`_.\n",
    "    Args:\n",
    "        confusion_matrix_numpy (np.array((num_classes, num_classes)) :\n",
    "        labels (list) :\n",
    "    Returns:\n",
    "        confusion_matrix_pycm (pycm.ConfusionMatrix) :\n",
    "    .. _`pycm`: https://github.com/sepandhaghighi/pycm\n",
    "    .. _`sklearn confusion matrix`:\n",
    "        https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "    \"\"\"\n",
    "    # Create empty dict to be used as input for pycm (see https://github.com/sepandhaghighi/pycm#direct-cm)\n",
    "    confusion_matrix_dict = {}\n",
    "\n",
    "    # Find number and classes and check labels\n",
    "    num_classes = np.shape(confusion_matrix_numpy)[0]\n",
    "    if not labels:  # If no labels are provided just use [0, 1, ..., num_classes]\n",
    "        labels = range(num_classes)\n",
    "    elif len(labels) != num_classes:\n",
    "        raise AttributeError(\"Number of provided labels does not match number of classes.\")\n",
    "\n",
    "    # Fill the dict in the format required by pycm with values from the sklearn confusion matrix\n",
    "    for row in range(num_classes):\n",
    "        row_dict = {}\n",
    "        for col in range(num_classes):\n",
    "            row_dict[str(labels[col])] = int(confusion_matrix_numpy[row, col])\n",
    "        confusion_matrix_dict[str(labels[row])] = row_dict\n",
    "\n",
    "    # Instantiate the pycm confusion matrix from the dict\n",
    "    confusion_matrix_pycm = ConfusionMatrix(matrix=confusion_matrix_dict)\n",
    "\n",
    "    return confusion_matrix_pycm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pycm_confusion_matrix = numpy_confusion_matrix_to_pycm(cnf_matrix, labels=class_names)\n",
    "#print(pycm_confusion_matrix.ACC)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
